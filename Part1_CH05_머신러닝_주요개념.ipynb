{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 분류와 회기\n",
    "- 분류 : 타깃값이 범주형 데이터\n",
    "- 회귀 : 타깃값이 수치형 데이터\n",
    "\n",
    "### 5.1.1 분류 (Classification)\n",
    "- 주어진 feature에 따라 대상을 유한한 범주로 구분하는 방법\n",
    "- 이진분류 (binary classification) : 타깃값이 2개\n",
    "- 다중분류 (multiclass classification) : 타깃값이 3개 이상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 회귀 (Regression)\n",
    "- 독립변수와 종속변수 간 관계 모델링\n",
    "    - 종속변수는 수치형 데이터\n",
    "- 독립변수 (independent variable) : 영향을 미치는 변수\n",
    "- 종속변수 (dependent variable) : 영향을 받는 변수\n",
    "- 단순 선형 회귀 (simple linear regression) : 독립변수 1 종속변수 1\n",
    "- 다중 선형 회귀 (multiple linear regression) : 독립변수 여러개 종속변수 1\n",
    "- 회귀 문제에서는 관계를 기반으로 최적의 회귀계수 (regression coefficient)를 찾아냄\n",
    "\n",
    "#### 5.1.2.1 상관계수 (correlation coefficient)\n",
    "- 상관관계 (correlation) 정도를 수치로 나타냄\n",
    "- 피어슨 상관계수 (pearson correlation coefficient) : \n",
    "    - 강도 (strength)와 방향 (direction)\n",
    "    - -1 < r < 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5.2 회귀 평가지표\n",
    "- MAE (Mean Absolute Error) : 평균 절대 오차 \n",
    "- MSE (Mean squared Error) : 평균 제곱 오차\n",
    "- RMSE (Root Mean Squared Error) : 평균 제곱근 오차\n",
    "- MSLE (Mean Squared Log Error) : 타깃값에 log를 취한 MSE\n",
    "    - log(y+1) : 로그값이 음의 무한대가 되는 상황을 방지\n",
    "- RMSLE (Root Mean Squared Log Error) : MLSE에 제곱근을 취한 값\n",
    "- R2 : 결정계수 (예측 타깃값의 분산 / 실제 타깃값의 분산)\n",
    "    - 1에 가까울수록 좋은 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = np.array([1, 2, 3, 2, 3, 5, 4, 6, 5, 6, 7, 8, 8])\n",
    "preds = np.array([1, 1, 2, 2, 3, 4, 4, 5, 5, 7, 7, 6, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(true, preds)\n",
    "MSE = mean_squared_error(true, preds)\n",
    "RMSE = np.sqrt(MSE)\n",
    "MSLE = mean_squared_log_error(true, preds)\n",
    "RMSLE = np.sqrt(MSLE)\n",
    "R2 = r2_score(true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\t 0.5385\n",
      "MSE:\t 0.6923\n",
      "RMSE:\t 0.8321\n",
      "MSLE:\t 0.0296\n",
      "RMSLE:\t 0.1721\n",
      "R2:\t 0.8617\n"
     ]
    }
   ],
   "source": [
    "print(f'MAE:\\t {MAE:.4f}')\n",
    "print(f'MSE:\\t {MSE:.4f}')\n",
    "print(f'RMSE:\\t {RMSE:.4f}')\n",
    "print(f'MSLE:\\t {MSLE:.4f}')\n",
    "print(f'RMSLE:\\t {RMSLE:.4f}')\n",
    "print(f'R2:\\t {R2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 분류 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 오차 행렬 (confusion matrix)\n",
    "- 실제 타깃값과 예측한 타깃값이 어떻게 \"매칭\"되는지 표현\n",
    "- T로 시작하면 올바른 예측, F로 시작하면 틀린 예측\n",
    "\n",
    "![Alt text](image-1.png)\n",
    "\n",
    "- 오차 행렬을 활용한 평가 지표는 값이 클 수록 좋음\n",
    "    - 타깃 예측값은 이산값(discrete value)으로 구해야 함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1.1 정확도 (accuracy)\n",
    "**(TP + TN) / (TP + FP + FN + TN)**\n",
    "- 실젯값과 에측값이 얼마나 일치되는지의 비율\n",
    "- 높은 정확도가 모델의 우수성을 담보하지 않음\n",
    "    - 평가지표로 잘 사용되지 않음\n",
    "\n",
    "#### 5.3.1.1 정밀도 (precision)\n",
    "**(TP) / (TP + FP)**\n",
    "- 양성 예측의 정확도\n",
    "- 음성을 양성으로 잘못 판단하면 문제가 발생하는 경우 사용\n",
    "    - 양성 : 문제가 되는 상태\n",
    "    - 음성 : 정상인 상태\n",
    "\n",
    "#### 5.3.1.1 재현율 (recall)\n",
    "**(TP) / (TP + FN)**\n",
    "- 실제 양성값 중 양성으로 잘 예측한 비율\n",
    "- 민감도 (sensitivity), 참 양성 비율 (true positive rate)와 같음\n",
    "- 양성을 음성으로 잘못 판단하면 문제가 되는 경우 사용\n",
    "\n",
    "#### 5.3.1.1 F1 점수\n",
    "**2 * (precision * recall) / (precision + recall)**\n",
    "- 정밀도와 재현율을 조합한 평가지표\n",
    "- 정밀도와 재현율의 조화 평균으로 구함\n",
    "    - 조화평균 : 주어진 수들의 역수의 평균의 역수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 로그 손실\n",
    "\n",
    "### 5.3.3 ROC 곡선과 AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 데이터 인코딩 (data encoding)\n",
    "\n",
    "### 5.4.1 레이블 인코딩 (label encoding)\n",
    "- 범주형 데이터와 숫자의 1:1 매핑\n",
    "- LabelEncoder : 1차원 데이터\n",
    "- OrdinalEncoder : 2차원 데이터\n",
    "- 단점 : 가까운 숫자를 비슷한 데이터라고 판단 => 원-핫 인코딩으로 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 인코딩 적용 후 데이터 :  [3 2 1 0 2 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "fruits = ['사과', '블루베리', '바나나', '귤', '블루베리', '바나나', '바나나', '사과']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "fruits_label_encoded = label_encoder.fit_transform(fruits)\n",
    "\n",
    "# 사전 순으로 번호를 매김\n",
    "print('레이블 인코딩 적용 후 데이터 : ', fruits_label_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 원-핫 인코딩 (one-hot encoding)\n",
    "- 여러 값 중 하나만 성화 하는 인코딩\n",
    "    1. feature의 고윳값 개수\n",
    "    2. 고윳값 개수만큼 열 추가\n",
    "    3. 고윳값에 해당하는 열에 1표시, 나머지는 0\n",
    "- 단점 : column이 지나치게 만아짐\n",
    "- 해결 방법 : \n",
    "    1. 비슷한 고윳값끼리 그룹화\n",
    "    2. 빈도가 낮은 고윳값끼리 '기타'로 그룹화\n",
    "    3. 다른 인코딩 적용 (타깃 인코딩, 프리퀀시 인코딩 등)\n",
    "* 교윳값 개수가 많아도 데이터 크기가 크지 않다면 그냥 원-핫 인코딩 적용\n",
    "\n",
    "- pandas의 get_dummies와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 2)\t1.0\n",
      "  (5, 1)\t1.0\n",
      "  (6, 1)\t1.0\n",
      "  (7, 3)\t1.0\n",
      "원-핫 인코딩 적용 후 데이터 : \n",
      " [[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "fruits = ['사과', '블루베리', '바나나', '귤', '블루베리', '바나나', '바나나', '사과']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder()\n",
    "\n",
    "fruits_label_encoded = label_encoder.fit_transform(fruits)\n",
    "fruits_onehot_encoded = onehot_encoder.fit_transform(fruits_label_encoded.reshape(-1, 1))\n",
    "\n",
    "# 대부분의 값이 0인 희소행렬은 메모리 낭비가 심함 => 압축형태인 CSR (Compressed Sparse Row) 행렬로 반환\n",
    "print(fruits_onehot_encoded)\n",
    "\n",
    "# toarray() : CSR 행열을 일반 배열로 바꿔줌\n",
    "print('원-핫 인코딩 적용 후 데이터 : \\n', fruits_onehot_encoded.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>귤</th>\n",
       "      <th>바나나</th>\n",
       "      <th>블루베리</th>\n",
       "      <th>사과</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   귤  바나나  블루베리  사과\n",
       "0  0    0     0   1\n",
       "1  0    0     1   0\n",
       "2  0    1     0   0\n",
       "3  1    0     0   0\n",
       "4  0    0     1   0\n",
       "5  0    1     0   0\n",
       "6  0    1     0   0\n",
       "7  0    0     0   1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.get_dummies(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 피처 스케일링 (feature scaling)\n",
    "- 서로 다른 feature 값의 범위 (max-min)이 일치하도록 조정\n",
    "- 트리 기반 모델은 feature scaling이 필요 없음 (random forest, XGBoost, LightGBM)\n",
    "    - 대소 관계에 영향을 받기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 min-max 정규화 (min-max normalization)\n",
    "- feature 값의 범위를 0 ~ 1로 조정\n",
    "\n",
    "    **(x - xmin) / (xmax - xmin)**\n",
    "- 이상치가 너무 크거나 작을 때느 표준화 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      키  몸무게\n",
      "광일  1.7   75\n",
      "혜성  1.5   55\n",
      "덕수  1.8   60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "height_weight_dict = {'키' : [1.7, 1.5, 1.8], '몸무게' : [75, 55, 60]}\n",
    "df = pd.DataFrame(height_weight_dict, index=['광일', '혜성', '덕수'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66666667 1.        ]\n",
      " [0.         0.        ]\n",
      " [1.         0.25      ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# 한 데이터에 맞춰놓은 스케일링 범위를 다른 데이터에도 적용하려면 fit과 transform을 분리\n",
    "scaler.fit(df)\n",
    "df_scaled = scaler.transform(df)\n",
    "\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 표준화 (standardization)\n",
    "- 평균이 0, 분산이 1이 되도록 feature 값 조정\n",
    "\n",
    "    **(x-average) / standard deviation**\n",
    "\n",
    "- 상한, 하한을 따로 정해야 하는 경우가 아니라면 적용\n",
    "- 정규분포를 따르는 데이터는 표준화 권장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.26726124  1.37281295]\n",
      " [-1.33630621 -0.98058068]\n",
      " [ 1.06904497 -0.39223227]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 교차검증\n",
    "- 이유 : \n",
    "    1. 모델이 과대적합될 가능성이 있음\n",
    "    2. 제출 전까지 모델 성능 확인이 어려움\n",
    "\n",
    "### 5.6.1 K 폴드 교차검증 (K-Fold Cross Validation)\n",
    "1. 전체 훈련 데이터를 K개로 나눔\n",
    "2. 하나는 검증 데이터, 나머지는 훈련 데이터로 지정\n",
    "3. 훈련 데이터로 모델을 훈련하고 검증 데이터로 평가\n",
    "4. 평가점수 기록\n",
    "5. 검증 데이터를 바꿔가며 2-4 반복\n",
    "6. K개의 검증 평가점수의 평균을 구함\n",
    "\n",
    "- 데이터의 편향 분포를 방지하기 위해 폴드로 나누기 전 데이터를 섞어주는 것이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 : [0 3 4 5 6 7 8 9], 검증 데이터 : [1 2]\n",
      "훈련 데이터 : [0 1 2 3 4 5 7 8], 검증 데이터 : [6 9]\n",
      "훈련 데이터 : [1 2 3 5 6 7 8 9], 검증 데이터 : [0 4]\n",
      "훈련 데이터 : [0 1 2 4 5 6 8 9], 검증 데이터 : [3 7]\n",
      "훈련 데이터 : [0 1 2 3 4 6 7 9], 검증 데이터 : [5 8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "#folds = KFold(n_splits=5, shuffle=False)\n",
    "folds = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train_idx, valid_idx in folds.split(data) :\n",
    "    print(f'훈련 데이터 : {data[train_idx]}, 검증 데이터 : {data[valid_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.2 층화 K 폴드 교차검증 (Stratified K-Fold Cross Validation)\n",
    "- 타깃값이 불균형하게 분포되어 있는 경우 사용\n",
    "- 분류 문제에서만 쓰임\n",
    "    - 회귀 문제의 타깃값은 연속된 값이라서 폴드마다 균등한 비율로 나누는 것이 불가능\n",
    "- StratifiedKFold의 split()함수에는 feature와 타깃값 모두를 전달 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 검증 데이터 타깃 값 : \n",
      "['일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Fold 2 검증 데이터 타깃 값 : \n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Fold 3 검증 데이터 타깃 값 : \n",
      "['스팸' '스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Fold 4 검증 데이터 타깃 값 : \n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Fold 5 검증 데이터 타깃 값 : \n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# '스팸'이 들어있지 않은 폴드 존재 => 층화 K 폴드 사용\n",
    "\n",
    "y = np.array(['스팸']*5 + ['일반']*45)\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(y)) :\n",
    "    print(f'Fold {idx+1} 검증 데이터 타깃 값 : ')\n",
    "    print(y[valid_idx], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 검증 데이터 타깃 값 : \n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Fold 2 검증 데이터 타깃 값 : \n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Fold 3 검증 데이터 타깃 값 : \n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Fold 4 검증 데이터 타깃 값 : \n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Fold 5 검증 데이터 타깃 값 : \n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.array(range(50))\n",
    "y = np.array(['스팸']*5 + ['일반']*45)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)) :\n",
    "    print(f'Fold {idx+1} 검증 데이터 타깃 값 : ')\n",
    "    print(y[valid_idx], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
